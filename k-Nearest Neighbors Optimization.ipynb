{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jasper Kyle Catapang - University of the Philippines Manila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors Classification Algorithm Proposed Optimization\n",
    "In pattern recognition, the k-nearest neighbors algorithm (k-NN) is a non-parametric method used for classification and regression. In both cases, the input consists of the k closest training examples in the feature space.\n",
    "\n",
    "In the k-nearest neighbor algorithm (k-NN), the determination of classes for test instances is usually performed via\n",
    "a majority vote system, which may ignore the similarities among data. In this research, the researcher proposes an approach to\n",
    "fine-tune the selection of neighbors to be passed to the majority vote system through the construction of a random n-dimensional\n",
    "hyperstructure around the test instance by introducing a new threshold parameter. The accuracy of the proposed k-NN algorithm is 85.71%, while the accuracy of the conventional k-NN algorithm is 80.95%, when performed on the Haberman’s Cancer Survival dataset—and 94.44% for the proposed k-NN algorithm, compared to the conventional’s 88.89% accuracy score on the Seeds dataset. The proposed k-NN algorithm is also on par with the conventional support vector machine algorithm accuracy, even on the Banknote Authentication and Iris datasets, even surpassing the accuracy of support vector machine on the Seeds dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('iris.txt')\n",
    "dataset = dataset.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal_length</th>\n",
       "      <td>150.0</td>\n",
       "      <td>15.386667</td>\n",
       "      <td>8.175743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal_width</th>\n",
       "      <td>150.0</td>\n",
       "      <td>9.573333</td>\n",
       "      <td>4.323103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_length</th>\n",
       "      <td>150.0</td>\n",
       "      <td>18.193333</td>\n",
       "      <td>11.656549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_width</th>\n",
       "      <td>150.0</td>\n",
       "      <td>8.993333</td>\n",
       "      <td>6.396829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>150.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count       mean        std  min  25%   50%   75%   max\n",
       "sepal_length  150.0  15.386667   8.175743  0.0  8.0  15.0  21.0  34.0\n",
       "sepal_width   150.0   9.573333   4.323103  0.0  7.0   9.0  12.0  22.0\n",
       "petal_length  150.0  18.193333  11.656549  0.0  6.0  19.5  27.0  42.0\n",
       "petal_width   150.0   8.993333   6.396829  0.0  2.0   9.0  14.0  21.0\n",
       "class         150.0   1.000000   0.819232  0.0  0.0   1.0   2.0   2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = dataset.shape[1]\n",
    "# Splitting the dataset in independent and dependent variables\n",
    "X = dataset.iloc[:,:dimensions].values #first n columns are the features\n",
    "y = dataset.iloc[:,-1].values #last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the training set and test set\n",
    "test_size = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 30\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling to bring the variable in a single scale\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection, k-fold cross-validation, and fitting of the conventional model\n",
    "Cross-validation is commonly used in applied machine learning to compare and select a model for a given predictive modeling problem because it is easy to understand, easy to implement, and results in skill estimates that generally have a lower bias than other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conventional's mean accuracy:  1.0 , k value: 5\n"
     ]
    }
   ],
   "source": [
    "# Creating list of K for KNN\n",
    "k_list = list(range(1,20,2))\n",
    "k_list = [5]\n",
    "# Creating list of cv scores\n",
    "cv_scores = []\n",
    "k_val_scores = []\n",
    "\n",
    "# Perform 5-fold cross validation\n",
    "for k in k_list:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    #print(k, y_test, y_pred)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    cv_scores.append(score)\n",
    "    k_val_scores.append(k)\n",
    "print(\"Conventional's mean accuracy: \", max(cv_scores), \", k value:\", k_val_scores[cv_scores.index(max(cv_scores))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimination of training points outside generated convex-hulls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bounded(p, hull):\n",
    "    \"\"\"\n",
    "    Test if points in `p` are in `hull`\n",
    "\n",
    "    `p` should be a `NxK` coordinates of `N` points in `K` dimensions\n",
    "    `hull` is either a scipy.spatial.Delaunay object or the `MxK` array of the \n",
    "    coordinates of `M` points in `K`dimensions for which Delaunay triangulation\n",
    "    will be computed\n",
    "    \"\"\"\n",
    "    from scipy.spatial import Delaunay\n",
    "    if not isinstance(hull,Delaunay):\n",
    "        hull = Delaunay(hull)\n",
    "        simplex = hull.find_simplex(p)>=0\n",
    "    return simplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample # 2 out of 30\n",
      "Training sample # 3 out of 30\n",
      "Training sample # 4 out of 30\n",
      "Training sample # 5 out of 30\n",
      "Training sample # 6 out of 30\n",
      "Training sample # 7 out of 30\n",
      "Training sample # 8 out of 30\n",
      "Training sample # 9 out of 30\n",
      "Training sample # 10 out of 30\n",
      "Training sample # 11 out of 30\n",
      "Training sample # 12 out of 30\n",
      "Training sample # 13 out of 30\n",
      "Training sample # 14 out of 30\n",
      "Training sample # 15 out of 30\n",
      "Training sample # 16 out of 30\n",
      "Training sample # 17 out of 30\n",
      "Training sample # 18 out of 30\n",
      "Training sample # 19 out of 30\n",
      "Training sample # 20 out of 30\n",
      "Training sample # 21 out of 30\n",
      "Training sample # 22 out of 30\n",
      "Training sample # 23 out of 30\n",
      "Training sample # 24 out of 30\n",
      "Training sample # 25 out of 30\n",
      "Training sample # 26 out of 30\n",
      "Training sample # 27 out of 30\n",
      "Training sample # 28 out of 30\n",
      "Training sample # 29 out of 30\n",
      "Training sample # 30 out of 30\n",
      "\n",
      "Proposed's mean unbounded count of neighbors:  7\n"
     ]
    }
   ],
   "source": [
    "threshold = 35\n",
    "verbose = True\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "unbounded_count = 0\n",
    "unbounded_count_list = []\n",
    "scores = []\n",
    "mean_score = 0\n",
    "\n",
    "orig_X_train = X_train\n",
    "orig_y_train = y_train\n",
    "\n",
    "progress = int(len(X_test)/25)\n",
    "progress_list = list(range(progress, len(X_test)+1, progress))\n",
    "\n",
    "#print(len(X_train), len(y_train))\n",
    "for x in X_test:\n",
    "    if verbose:\n",
    "        if j in progress_list:\n",
    "            print(\"Training sample #\", j+1, \"out of\", len(X_test))\n",
    "        elif j == len(X_test)-1:\n",
    "            print(\"Training sample #\", j+1, \"out of\", len(X_test))\n",
    "    if threshold != 0:\n",
    "        minimum = min(x)\n",
    "        maximum = max(x)\n",
    "        bound = np.random.random_integers(minimum-threshold, maximum+threshold, (4*(dimensions-1), dimensions))\n",
    "\n",
    "        for xi in X_train:\n",
    "            if not is_bounded(xi, bound):\n",
    "                unbounded_count += 1\n",
    "                #print(\"Unbounded: \"+str(xi))\n",
    "                try:\n",
    "                    X_train = np.delete(X_train, i, 0)\n",
    "                    y_train = np.delete(y_train, i)\n",
    "                except:\n",
    "                    continue\n",
    "            i = i+1\n",
    "\n",
    "    i = 0\n",
    "    unbounded_count_list.append(unbounded_count)\n",
    "    unbounded_count = 0\n",
    "    #print(len(X_train), len(y_train))\n",
    "    \n",
    "    k = k_val_scores[cv_scores.index(max(cv_scores))]\n",
    "    knn = KNeighborsClassifier(n_neighbors = k, n_jobs=-1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict([x])\n",
    "    #print(y_test[j], y_pred[0])\n",
    "    if y_test[j] == y_pred[0]:\n",
    "        scores.append(1.0)\n",
    "    else:\n",
    "        scores.append(0.0)\n",
    "    \n",
    "    X_train = orig_X_train\n",
    "    y_train = orig_y_train\n",
    "    j = j+1\n",
    "\n",
    "mean_score = mean(scores)\n",
    "print(\"\\nProposed's mean unbounded count of neighbors: \", int(mean(unbounded_count_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed's mean accuracy:  1.0 , k value: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Proposed's mean accuracy: \", mean_score, \", k value:\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
